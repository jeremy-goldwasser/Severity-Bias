\documentclass{article}

\input{macros}
\usepackage{adjustbox}
\renewcommand{\hat}{\widehat} % DJM: I find the regular hat hard to see
\newcommand{\given}{\, \vert \,}
\DeclareMathOperator{\bias}{Bias}

\usepackage{xcolor}
\newcommand{\ahcomment}[1]{{\color{red}[AH: #1]}}
\newcommand{\rjtcomment}[1]{{\color{purple}[RJT: #1]}}
\newcommand{\djmcomment}[1]{{\color{teal}[DJM: #1]}}
\newcommand{\jmgcomment}[1]{{\color{cyan}[JMG: #1]}}

\title{Challenges in Estimating Time-Varying Epidemic Severity Rates from
  Aggregate Data} 

\author{Jeremy Goldwasser\thanks{Department of Statistics, University of
    California, Berkeley} 
  \and  
  Addison J.\ Hu\thanks{Department of Statistics, Carnegie Mellon University}
  \and 
  Alyssa Bilinski\thanks{Departments of Health Policy and Biostatistics, Brown University} 
  \and
  Daniel J.\ McDonald\thanks{Department of Statistics, University of British
    Columbia} 
  \and 
  Ryan J.\ Tibshirani\footnotemark[1]}

\date{}

\begin{document}
\maketitle

\begin{abstract}
Severity rates like the case-fatality rate and infection-fatality rate are
key metrics in public health. To guide decision-making in response to changes
like new variants or vaccines, it is imperative to understand how these rates
shift in real time. In practice, time-varying severity rates are typically
estimated using a ratio of aggregate counts. We demonstrate that these
estimators are capable of exhibiting large statistical biases, with concerning
implications for public health practice, as they may fail to detect heightened 
risks or falsely signal nonexistent surges. We supplement our mathematical 
analyses with experimental results on real and simulated COVID-19 data. Finally,
we discuss strategies to mitigate this bias, drawing connections with
effective reproduction number ($R_t$) estimation.    
\end{abstract}

\section*{Author Summary}
Public health authorities use severity rates to track the deadliness of a disease over the course of an epidemic. 
Typically, metrics like the case-fatality are estimated in real time by dividing the number of new deaths by the number of recently reported infections. 
In our study, we reveal that this simple calculation can be seriously misleading, posing large problems for public health decision-making.
When severity rates are underestimated, officials can miss genuine rises in risk and postpone critical interventions, putting more people in harm’s way.
Conversely, when these metrics are overestimated, authorities may enact needless restrictions and stoke undue public fear, wasting resources and eroding trust.
We illustrate these issues with both mathematical analysis and empirical validation on real and simulated COVID-19 data. 
In addition, we provide practical guidelines for interpreting ratio estimators, ensuring more reliable severity tracking and better-timed interventions.
Finally, we survey promising alternatives from recent literature, and suggest techniques to improve upon them.

\section{Introduction}

Several public health metrics of interest express the probability that a second,
often more severe outcome will follow a primary event. 
We refer to such metrics as ``severity rates.''
These include well-known examples such as the case-fatality rate (CFR) and infection-fatality rate (IFR), commonly used to assess the deadliness of an epidemic \citep{nishiuraEx1, nishiuraEx2, timevar_ifr, lancet_ifr}. 
Another important example 
  % Another central example of a
% ``severity rate'', which is a term that we use for metrics of this general form,
is the hospitalization-fatality rate (HFR) \citep{HFR_linelist3, HFR_linelist1,  
  HFR_linelist2}.

In an ideal setting, severity rates can be obtained directly from a
comprehensive line-list or claims data set containing individual patient
outcomes \citep{HFR_linelist3, cfr_line_list}.
However, large-scale tracking of individuals in fast-moving epidemics
has been infeasible, especially in real time. 
For example, the CDC's line list during the COVID-19 pandemic excluded large geographic regions, was only updated monthly, and had missing death statuses for a high proportion of individuals \citep{CDC_line_list}.
Instead, severity
rates are routinely estimated from aggregate count data. 
Aggregate 
case and death counts were widely used to estimate and report COVID-19 CFRs in the academic literature \citep{yuan2020monitoring,
  horita2022global, LIU2023100350, germany}, as well as in major news outlets including
The Atlantic \citep{atlantic}, Wall Street Journal \citep{wsj}, and New York Times \citep{nyt}. 
They were also used by public health organizations like the CDC \citep{ahmad2023covid,mississippi}, and reported by the Trump and Biden administrations \citep{whitehouse2020mcenany, whitehouse2021briefing}. 


Several works 
assume severity rates are constant in time \citep{nishiuraEx1, ghani, jewell2007nonparametric, reich2012estimating, lancet_controversial}. However, 
consequential shifts can occur in response to factors 
such as new therapeutics, vaccines, and variants. 
Therefore, many works estimate time-varying severity rates from aggregate data streams.
Standard real-time approaches do so with a ratio of primary and secondary counts.
% Time-varying severity rates are often estimated with a
% ratio of primary and secondary aggregate data streams. 
In fact, ratio estimators are so common that CFR is often 
(mis)labeled the case-fatality \emph{ratio} \citep{timevar_ifr}. 

In this work, we show that these ratio estimators are prone to nontrivial
statistical bias. 
We empirically validate our mathematical analysis, 
tracking the hospitalization-fatality rate (HFR) during COVID-19.
Bias arises as a consequence of changing severity
rates---
precisely what time-varying estimates are employed to detect.
For example, the ratio estimators failed to quickly signal increased
risk in the onset of the Delta wave.
Bias also arises due to misspecification of the delay distribution that relates primary and secondary events. 
This is particularly troublesome during various stages of a surge, especially for the popular lagged ratio.
Once again, these are periods in which it is critical to properly ascertain the severity rate.
While the HFRs dropped in the aftermath of the initial Omicron surge, the lagged ratio's estimates jumped 50\% above the true values.

We provide practical heuristics for when epidemiologists should expect this bias in practice. 
These may prevent poor decision-making based on biased estimates of severity rates. 
More broadly, our work exposes the limitations of existing approaches, motivating the use of alternatives.
We point towards methodology which may avoid this bias, and offer suggestions to improve it.
Code to reproduce our experimental results is available at \texttt{https://github.com/jeremy-goldwasser/Severity-Bias}.

\section{Methods}
\label{sec:methods}

In this section, we introduce the main estimators we study, and analyze their 
bias. Subsequently, we detail the data used for empirical study and validation. 

\subsection{Severity rate estimators}
\label{sec:defs}

Severity rates convey the probability that a primary event will result in a
secondary event in the future. In the case of CFR, for example, a primary event
is a positive COVID-19 case and a secondary event is a death with a positive
test result. Formally, a time-varying severity rate at time $t$ is generally
defined as:  
\begin{equation}
\label{eq:severity}
p_t = \P(\text{secondary event will occur} \given \text{primary event at time 
  $t$}).   
\end{equation}
Here, $t$ may represent a discrete interval of time, such as a given day or 
week. It also may be understood in a continuous-time fashion. Although this will    
not be our focus in this paper, the same general principles apply in the
continuous-time case. For simplicity, we will consider only the discrete-time 
setting, and we index time steps via integers, as in $t=0,1,2,\dots$.    

Throughout, we denote by $\{X_t\}$ and $\{Y_t\}$ the aggregate time series of 
new primary and secondary events, respectively. These are often counts, and we
will generally refer to them as such. At time $t$, we assume data for all past
$s \leq t$ is available, but future data is not. Therefore real-time estimates of
$p_t$ can only rely on past counts \smash{$\{X_s\}_{s\leq t}$} and
\smash{$\{Y_s\}_{s\leq t}$}. In practice, to stabilize estimates, smoothed
counts are often used in place of raw counts. This may be simply absorbed into 
the notation for $X_t$ and $Y_t$, and we do not address smoothing explicitly in
the formulation of the estimators, but refer back to this issue in Section
\ref{sec:setup}.  

\paragraph{Lagged estimator.} 

The canonical estimator for time-varying severity rates is a ratio between
the counts of primary and secondary events, offset by a lag $\ell$. This
estimator is widely-used in epidemiology, both in the academic literature and in 
public health practice and communication (e.g., \citealp{wsj, atlantic,
  yuan2020monitoring, timevar_ifr, thomas2021estimating, horita2022global,
  LIU2023100350, germany}). For concreteness, we define the \emph{lagged ratio} 
at time $t$ as:   
\begin{equation}
\label{eq:lagged}
\hat{p}_t^\ell = \frac{Y_t}{X_{t-\ell}},
\end{equation}
where $\ell \geq 0$ is a given parameter (often chosen to maximize
cross-correlation between $\{X_t\}$ and $\{Y_t\}$).      

\paragraph{Convolutional estimator.} 

Alternative methods for estimating severity rates utilize a delay distribution,
which relates the two time series. The delay distribution at time $t$ and lag
$k$ is defined as: 
\[
\pi_k^{(t)} = \P(\text{secondary event at $t+k$} \given \text{primary event at
  $t$, secondary event occurs}).  
\]

Throughout this work, we assume that the delay distribution has a finite support
of $d$ time steps. 
For the sake of notational convenience, we also assume the delay distribution is stationary:
\smash{$\pi_k^{(t)} = \pi_k$} for all $k$ and $t$. 
However, our analyses hold in the case of time-varying delay distributions.
% (In reality, delay
% distributions may themselves be time-varying, and this creates its own set of
% challenges, which only exacerbate the ones we highlight in this paper for a
% fixed delay distribution.) 
While the delay distribution is generally unknown,
several tools exist to estimate them from aggregate or line-list data; see
\citealp{delay_distrs} for a review. Given $\pi$, we can express the
expected number of secondary events at time $t$ as follows: 
\begin{align}
\E[Y_t \given \{X_s\}_{s\leq t}]
&= \sum_{k=0}^d X_{t-k} \P(\text{secondary at $t$} \given \text{primary at
  $t-k$}) \nonumber \\   
&= \sum_{k=0}^d X_{t-k} \P(\text{secondary after $k$ time steps} \given
  \text{secondary occurs, primary at $t-k$}) \nonumber \\
&\hspace{200pt} \times\P(\text{secondary occurs} \given\text{primary at $t-k$})
  \nonumber \\  
\label{eq:model}
&= \sum_{k=0}^d X_{t-k} \pi_k p_{t-k}.
\end{align}

This is a convolution of the delay distribution against the product of primary
incidence and the severity rate. If the severity rate remains constant, $p_{t-k}
= p_t$ for all $k$ between $0$ and $d$, then the expression in \eqref{eq:model}
simplifies to \smash{$\E[Y_t \given \{X_s\}_{s\leq t}] = p_t \sum_{k=0}^d
  X_{t-k} \pi_k$}. As studied in \citet{UKpaper}, we can rearrange this
relationship in order to estimate the severity rate at $t$, after plugging-in an
estimate $\gamma$ of the delay distribution $\pi$:   
\begin{equation}
\label{eq:conv}
\hat{p}_t^\gamma = \frac{Y_t}{\sum_{k=0}^d X_{t-k} \gamma_k}.
\end{equation}

We call this the \emph{convolutional ratio} estimator of the severity rate. The superscript in our notation \smash{$\hat{p}_t^\gamma$} emphasizes that
$\gamma$ is the distribution used in the definition of the estimator
\eqref{eq:conv}. To reiterate, in moving from \eqref{eq:model} to
\eqref{eq:conv}, we are implicitly assuming that the severity rate $p_t$ is
stationary over the interval of time from $t-d$ and $t$. Of course, this runs in
contradiction to the fact that we are trying to estimate a time-varying severity
rate in the first place. As we will see shortly, this can create significant
bias in the convolutional ratio.  

Some further comments are in order. The convolutional ratio has a longer history
of study and use in the literature on estimating stationary severity
rates. Indeed, \citet{nishiura} developed the estimator in this setting,  
and used it to analyze the CFR in the H1N1 influenza pandemic of 2009. (The main 
difference to \eqref{eq:conv} is that in the stationary case we aggregate both
the numerator and denominator over all past data.) This estimator, which is
sometimes called the \emph{delay-adjusted} estimator of the severity rate, is
popular in the academic literature and public health practice (e.g., 
\citealp{nishiuraEx1, nishiuraEx2, Russell2020, Unnikrishnan2021}), though   
arguably less popular than the lagged ratio. The package \texttt{cfr}
\citep{cfr_package} gives an R implementation, for both the stationary and
time-varying cases.  

Furthermore, we note that \eqref{eq:conv} can be seen as a generalization of the  
lagged ratio estimator \eqref{eq:lagged}: when we take $\gamma$ to be a point
mass at lag $\ell$, i.e., $\gamma_\ell = 1$ and $\gamma_k = 0$ for all $k \not=
\ell$, then \eqref{eq:conv} reduces to \eqref{eq:lagged}.   

\paragraph{Connection with reproduction numbers.} 

Severity rates bear a natural connection with reproduction numbers. Both the
true severity rate as defined in \eqref{eq:severity} and the case reproduction
number $R_t$ are defined as the average number of secondary events produced by a
single primary event at $t$, but in contrast to severity rates, reproduction
numbers have infections as the primary and secondary events, where a single
infection can produce more than one follow-on infection. Playing the role of the
delay distribution $\pi$ in our setting is the generation interval distribution
in reproduction numbers, which measures the time in between primary and
secondary infections.  

Severity rates and reproduction numbers can also be estimated similarly. Because
primary events at $t$ produce secondary events after $t$, their effect is not
observed in real time. Therefore, standard real-time estimators for severity
rates \eqref{eq:lagged}, \eqref{eq:conv} and for $R_t$ both analyze the number
of  secondary events at $t$ produced by relevant primary events. In words, this 
adopts a ``backward-looking'' perspective that is possible in real time, rather the 
the ``forward-looking'' perspective inherent to the definition in
\eqref{eq:severity}. 

For reproduction numbers, the backward-looking quantity has its own name:
\emph{instantaneous} $R_t$, which is the average number of secondary infections
at time $t$ produced by a single primary infection in the past. One of the most
popular traditional estimators of instantaneous $R_t$ is based on an essentially 
identical idea to the convolutional ratio \citep{fraser2007, wallinga2007how}: 
\begin{equation}
\label{eq:instRt}
\hat{R}_t = \frac{I_t}{\sum_{k=1}^d I_{t-k} g_k}.
\end{equation}
Here, $I_t$ denotes the number of new infections at $t$, and $g$ is the
generation interval distribution. Note that the difference between
\eqref{eq:conv} and \eqref{eq:instRt} is that the latter uses the same aggregate 
time series, infections, in both the numerator and denominator. While more
modern frameworks for estimating instantaneous $R_t$ are often Bayesian (e.g.,
\citealp{cori2013new}), the underlying basic point estimates are still the same.
% By contrast, the popular estimator from \citet{wallinga_teunis} is analogous
% to equation \eqref{eq:severity}, but requires data after time $t$.    

\subsection{Well-specified analysis}
\label{sec:wellspecified}

First we analyze the bias of the convolutional ratio \eqref{eq:conv} in what we  
call the \emph{well-specified} case, where the true delay distribution $\pi$ is 
known. Formally, for an estimator \smash{$\hat{p}_t$} of $p_t$, we define its
bias as:     
\[
\bias(\hat{p}_t) = \E[\hat{p}_t \given \{X_s\}_{s\leq t}] - p_t. 
\]

\begin{proposition}
\label{prop:OracleBias}
Assume the true delay distribution $\pi$ is known.
The bias of the well-specified convolutional ratio \smash{$\hat{p}_t^\pi$} is 
\begin{equation}
\label{eq:OracleBias}
\bias(\hat{p}_t^\pi)  = \sum_{k=0}^d \Bigg[ \frac{X_{t-k}\pi_k}{\sum_{j=0}^d
  X_{t-j}\pi_j} (p_{t-k}-p_t) \Bigg]. 
\end{equation}
\end{proposition}

The proof of Proposition \ref{prop:OracleBias} is given in
Section S1.1 of the Supplement. 
% The bias \eqref{eq:OracleBias} of the
% convolutional ratio estimator of the severity rate depends on three factors,
% which we discuss next. 
Intuitively, the well-specified bias can be interpreted as a weighted average of the difference between trailing and current severity rates. 
The weights depend on the delay distribution and primary incidence curve.
Figure \ref{fig:wellspecified} provides an accompanying illustration.     

\begin{enumerate}
\item \textbf{Changes in severity rate}. The central component of this bias
  expression is the difference $p_{t-k}-p_t$. When the severity rate is constant
  over the $d$ preceding time points, the convolutional ratio is unbiased 
  (because this difference is zero). This falls in line with the motivation used
  to derive this estimator, as explained in the last subsection. But when 
  severity rates change before $t$, these difference terms will be nonzero, in
  which case the estimator will be generally biased. %\footnote{It is possible
   %that this estimator could still be unbiased in the unlikely event that
   %individual components in the summation over $k$ exactly cancel each other.}   
  Figure \ref{fig:toy_hfr} shows a simple example of this: the estimated
  severity rates are most inaccurate in periods where the true rate is changing
  quickly.        

  To make matters worse, the bias is in the opposite direction of the trend we 
  want to detect; for example, suppose the severity rate is monotonically
  falling, with $p_t < p_{t-1} < \dots < p_{t-d}$. The bias will then be
  positive, meaning the ratio estimates do not decline with the true rate. In
  fact, the estimated severity may even rise, not fall. Conversely, when true
  severity rates are rising, the estimates will be too low. 

\item \textbf{The delay distribution}. How much the changing severity rates
  impact the bias depends on the shape of the delay distribution $\pi$. In
  general, the bias will be greatest when the delay distribution has a long
  enough tail to upweight significant differences in severity rate. While this
  distinction may appear subtle, Section \ref{sec:results} highlights its
  surprisingly large effects. The simple example in Figure \ref{fig:toy_delay}
  also shows significant differences in bias between shorter and longer delay
  distributions.     

\item \textbf{The primary incidence curve.} Changing primary incidence $X_t$ 
  will also affect the bias, presuming the severity rate changes roughly 
  monotonically in the recent past. Intuitively, this up- or down-weights the
  terms $X_{t-k}\pi_k (p_{t-k} - p_t)$ at times further from the present, which  
  are likely to contribute the most bias. In general, falling primary incidences
  will amplify the bias, whereas rising events will minimize it. Figure
  \ref{fig:toy_primary} provides an illustration of this phenomenon.   
\end{enumerate}

\begin{figure}[htb]
\centering
\begin{subfigure}[b]{0.325\linewidth}
  \centering
  \includegraphics[width=\linewidth]{Figures/Simulated/toy_chging_hfr.pdf} 
  \caption{}
  \label{fig:toy_hfr}
\end{subfigure}
\begin{subfigure}[b]{0.325\linewidth}
  \centering
  \includegraphics[width=\linewidth]{Figures/Simulated/toy_delay_distr.pdf}
  \caption{}
  \label{fig:toy_delay}
\end{subfigure}
\begin{subfigure}[b]{0.325\linewidth}
  \centering
  \includegraphics[width=\linewidth]{Figures/Simulated/toy_chging_primary.pdf} 
  \caption{}
  \label{fig:toy_primary}
\end{subfigure}
\caption{Simple examples which illustrate the effects of the three factors
  explained above on 
  the bias of the well-specified convolutional ratio \eqref{eq:OracleBias}.
  In each figure, the colors correspond to different versions of the factor of interest.
  % the bias \eqref{eq:OracleBias} in estimating the severity rate. 
  The primary incidence curve measures COVID-19 hospital admissions, as
  reported to the HHS in early 2022. We then simulate a secondary incidence
  curve, COVID-19 deaths, from \eqref{eq:model}, without noise. The underlying  
  HFR curve $p_t$ and delay distribution $\pi$ used (in simulating deaths) were 
  derived from external data sources, as explained in more detail in Section
  \ref{sec:setup}. }      
\label{fig:wellspecified}
\end{figure}
      
Section S1.3 of the Supplement provides further analysis, by discussing 
simplified settings in which the bias \eqref{eq:OracleBias} described in
Proposition \ref{prop:OracleBias} itself simplifies in elucidating ways.   

\subsection{Misspecified analysis}
\label{sec:misspecified}

We now analyze the bias of the convolutional ratio \eqref{eq:conv} for an
arbitrary distribution $\gamma$. Recall that $\pi$ denotes the true delay
distribution in \eqref{eq:model}. We refer to the present as the
\emph{misspecified} case, as $\gamma$ may differ from $\pi$.    

% \begin{minipage}{\textwidth}
\begin{proposition}
\label{prop:MispBias}
The bias of the convolutional ratio \smash{$\hat{p}_t^\gamma$} (where the true 
delay distribution $\pi$ is unknown, and the working delay distribution $\gamma$
is arbitrary, but also supported on $d$ time steps) is
\begin{equation}
\label{eq:MispBias}
\bias(\hat{p}_t^\gamma) = A_t^\gamma \bias(\hat{p}_t^\pi) + p_t (A_t^\gamma-1),  
\end{equation}
where \smash{$A_t^\gamma = \sum_{j=0}^d X_{t-j}\pi_j \,\big/\, \sum_{j=0}^d 
  X_{t-j} \gamma_j$}. This compares how the delay distributions convolve against  
the most recent primary incidence levels. 
\end{proposition}
% \end{minipage}

The proof of Proposition \ref{prop:MispBias} is given in 
Section S1.2 of the Supplement. 
% Before delving into the technical details, we first provide an intuitive explanation for the special case of the lagged ratio. 
Before delving into the technical details, we first summarize its implications for the lagged ratio.
When primary incidence $\ell$ days ago is less than the average count weighted by the delay distribution, 
the lagged ratio is typically above the well-specified convolutional ratio. 
% the lagged ratio typically has higher bias than that of the well-specified convolutional ratio. 
Otherwise, when counts $\ell$ days ago exceed the delay-weighted average, 
it tends to lie below.
% the lagged bias tends to be lower.
This leads to the following heuristics, which we justify subsequently.
\begin{enumerate}
    \item \textbf{Heuristic \#1:} When primary incidence is climbing rapidly, the lagged ratio tends to overestimate severity, at least relative to the well-specified convolutional ratio.
    \item \textbf{Heuristic \#2:} As incidence falls swiftly, the lagged ratio may drop just as sharply, even if true severity has not changed.
    \item \textbf{Heuristic \#3:} Once incidence stabilizes after a decline, the lagged ratio can exhibit sudden, counterintuitive jumps.
\end{enumerate}


Under misspecification, the proposition gives an
additive decomposition \eqref{eq:MispBias} of the convolutional ratio bias,
based on the well-specified bias \smash{$\bias(\hat{p}_t^\pi)$} (as studied in
Proposition \ref{prop:OracleBias}), and a misspecification factor
\smash{$A_t^\gamma$}. At the outset, we note that if $\pi = \gamma$ (no  
misspecification), we have \smash{$A_t^\gamma = 1$}, and \eqref{eq:MispBias}
reduces to the well-specified bias. Generally, values of \smash{$A_t^\gamma >
  1$} amplify the oracle bias and add positive misspecification bias \smash{$p_t
  (A_t^\gamma-1) > 0$}; meanwhile, values of \smash{$A_t^\gamma < 1$} shrink the
oracle bias and add negative misspecification bias \smash{$p_t (A_t^\gamma-1) <
  0$}. 

Whether or not misspecification contributes a larger magnitude of bias overall
hence depends on whether or not the sign of the misspecification term \smash{$p_t 
  (A_t^\gamma-1)$} agrees with the sign of the oracle bias
\smash{$\bias(\hat{p}_t^\pi)$}. This need not always be the case, though in our
experience, it is often true in both real and simulated experiments, as we will
see in Section \ref{sec:results}. Here, to gain more insight, we study the
behavior of the bias in three settings: 
\begin{itemize} 
\item Smooth $\gamma$ with a lighter tail and smaller mean than $\pi$ (more mass
  concentrated at recent time points).    
\item Smooth $\gamma$ with a heavier tail and larger mean than $\pi$ (less mass
  concentrated at recent time points).    
\item Nonsmooth $\gamma$, with a point mass at lag $\ell$; we reiterate that in 
  this case the convolutional ratio reduces to the lagged ratio
  \smash{$\hat{p}_t^\ell$} in \eqref{eq:lagged}. We also note that its
  misspecification factor \smash{$A_t^\gamma$} reduces to a quantity we
  similarly denote \smash{$A_t^\ell = \sum_{j=0}^d X_{t-j}\pi_j \,\big/\,
    X_{t-\ell}$}, and its bias \eqref{eq:MispBias} reduces to: 
  \begin{equation}
  \label{eq:LagBias}
  \bias(\hat{p}_t^\ell) = \frac{\sum_{j=0}^d X_{t-j}\pi_j}{X_{t-\ell}}
  \bias(\hat{p}_t^\pi) + p_t \Bigg(\frac{\sum_{k=0}^d X_{t-k}\pi_k}{X_{t-\ell}}
  - 1 \Bigg).  
\end{equation}
\end{itemize}

We discuss the behavior of the bias in these three settings, as a function of
the primary incidence curve (which drives bias through the misspecification
factor \smash{$A_t^\gamma$}). Figure \ref{fig:misspecified} provides an
accompanying illustration.

\paragraph{Primary incidence rising.} 

Consider the case where primary events are rising---first slowly, then rapidly
before leveling off. A lighter-tailed $\gamma$ will place more weight
on recent time points, with higher counts, than $\pi$; thus \smash{$\sum_{j=0}^d  
  X_{t-j}\gamma_j > \sum_{j=0}^d X_{t-j}\pi_j$}, so \smash{$A_t^\gamma <
  1$}. The opposite occurs for a heavier-tailed $\gamma$: this
places more weight on distant low-count time points and less on the ongoing
surge, so \smash{$A_t^\gamma > 1$}. A point mass distribution $\gamma$ places
all of its mass on $X_{t-\ell}$, and during the steepest phase of the rise, this
is considerably less than $X_t$. The true delay $\pi$ distributes mass across
the  $d$ most recent time points, and a large fraction of its mass will be
convolved against the last $\ell-1$ time points, whose counts exceed
$X_{t-\ell}$. The times before $t-\ell$ have less of an offsetting effect, 
because incidence has risen at a  growing rate. Hence, during a surge we will 
see \smash{$X_{t-\ell} < \sum_{j=0}^d X_{t-j}\pi_j$}, and \smash{$A_t^\ell >
  1$}. However, the behavior of \smash{$A_t^\ell$} will be generally more
erratic than \smash{$A_t^\gamma$} for a smooth distribution $\gamma$, as the
denominator in the former is less smooth as $t$ varies. 

Figure \ref{fig:misspecified} visualizes this as hopitalizations (primary
events) rise between December 2021 and mid-January 2022. Throughout this period
\smash{$A_t^\gamma$} is below/above 1 for the light-tailed/heavy-tailed
$\gamma$. Meanwhile, \smash{$A_t^\ell$} spikes to 1.25 in early January.  
Correspondly, the lagged HFR rises to 20\% when the true one drops to 15\%.    

\begin{figure}[p]
\centering
\includegraphics[width=0.9\linewidth]{Figures/Simulated/toy_misp.pdf}
\caption{Examples of convolutional ratio estimates under misspecification of the
  delay distribution.
  As in Figure \ref{fig:wellspecified}, the primary events are COVID-19
  hospitalizations, as reported to the HHS, and secondary events are deaths 
  simulated noiselessly from \eqref{eq:model}. The underlying HFR curve $p_t$
  and delay distribution $\pi$ used in the simulation were fit using external
  data sources detailed shortly in Section \ref{sec:setup}. The lagged ratio
  estimator used $\ell=16$, chosen to maximize cross-correlation between
  hospitalizations and deaths.} 
\label{fig:misspecified}
\end{figure}

\paragraph{Primary incidence falling.}

Next assume primary incidence reaches a maximum and begins to fall. The smooth
distributions behave much the same as when incidence was rising. The light-tailed
distribution has more mass around the peak than $\pi$, so \smash{$A_t^\gamma < 
1$}. Conversely, \smash{$A_t^\gamma > 1$} for the heavier-tail distribution
because it convolves more mass before the top of the rise. The lagged bias
changes its behavior in this period; while \smash{$A_t^\ell$} had exceeded 1
before the peak, it quickly plunges below 1. At exactly $\ell$ time points after  
the peak, the lagged estimator attains the smallest possible value of
\smash{$A_t^\ell$}, as $X_{t-\ell}$ maximizes its denominator. Again, the
lagged ratio is likely to have larger fluctuations of \smash{$A_t^\ell$},
since its denominator reaches extremes that are not witnessed in
\smash{$A_t^\gamma$} (the convolution in the denominator of 
\smash{$A_t^\gamma$} acts as a smoother).   

In Figure \ref{fig:misspecified}, we can see \smash{$A_t^\ell$} drop below 0.8
near the start of February 2022; this happens precisely $\ell=16$ days after
daily new hospitalizations peak above 20,000 in mid-January. The lagged 
ratio falls from 20\% to 12.5\% accordingly, with the true HFR remains roughly
constant, hovering around 15\%. In the same period, the convolutional ratios
(with light- or heavy-tailed $\gamma$) stay quite close to the true HFR.   

\paragraph{Primary incidence levels out from a fall.}

The most jarring instance of misspecification bias occurs as primary incidence
levels out. The true delay distribution $\pi$ has a heavier tail than the
low-mean, light-tailed distribution $\gamma$. It also has a heavier tail than
the point mass distribution, which has no tail at all. This has important
implications as the peak of the surge fades into the past. Compared to $\pi$,
the light-tailed $\gamma$ and point mass distribution convolve little to no mass
with the high-count period of the wave. As a result, both \smash{$A_t^\gamma$}  
and \smash{$A_t^\ell$} rise above 1, and severity rate estimates spike. The
magnitude of this spike depends how quickly primary incidence is changing. 

Figure \ref{fig:misspecified} displays this false spike. Around the start of April 2022,
we see \smash{$A_t^\gamma$} (for light-tailed $\gamma$) and $A_t^\ell$ reach 
maximums near 1.25 and 1.68, respectively. Their corresponding HFR estimates reach
18\% and 25\% while the true HFR has fallen below 14\%. This is of course highly 
problematic as it signals a rise in severity at a very counterintuitive time,
when hospitalizations are at their lowest. The heavy-tailed delay $\gamma$ has
the opposite trend and underestimates the true HFR at this time, but by a
smaller amount. 

\subsection{Experimental setup}
\label{sec:setup}

Here we describe the data and general experimental setup used in Figures
\ref{fig:wellspecified} and \ref{fig:misspecified}, and in Section
\ref{sec:results}.    

\paragraph{Hospitalization-fatality rate.}

Our experiments analyze the HFR throughout the COVID-19 pandemic. While HFR 
may be less common as an object of study compared to CFR, it has a few
advantages. First and foremost, hospitalization reporting was much more complete
than case reporting throughout the pandemic. Hospitals were mandated to report
new daily COVID-19 admissions to the Department of Health and Human Services
(HHS) \citep{HHS2023}. Due to changes in case ascertainment over time (cases as
a fraction of infections), it is harder to interpret the CFR in a time-varying
fashion, i.e., harder to understand what precisely this is reflecting over the
course of the pandemic.  

A second advantage is that hospitalization counts published by the HHS are
aligned by admission date. This makes it more meaningful to interpret the HFR as
a reflection of severity, especially in a time-varying fashion. In comparison,
case counts as aggregated by John Hopkins University (JHU) \citep{JHU} (the
central resource for comprehensive COVID-19 case data in the US) are aligned by
report date. Extreme reporting delays (sometimes cases were reported 45 days
after infections, see, e.g., \citealp{Jahja2022}) make the CFR less meaningful
to study as a time-varying quantity, even outside of ascertainment issues.  

% \citet{Lancet_delays} studied a cohort in which the median infection-to-death 
% time was only 18 days. Nevertheless, negative case-to-death delays are
% uncommon enough that the same findings should apply for both CFR and HFR 
% \citet{nishiuraEx2, UKdelay}. 

Thirdly, we were able to find a good ``ground truth proxy'' for the national HFR 
during the COVID-19 pandemic, as published by the National Hospital Care Survey
(NHCS). This helps guide our simulations and also serves as validation data for
us, as we describe in more detail below.  

\paragraph{Aggregate data streams.}

To estimate the real-time HFR, we use aggregate counts of daily COVID-19 
hospitalizations and deaths as made available in the Epidata API
\citep{Epidata}, developed by the Delphi Group. Like HHS for hospitalizations,
the JHU Center for Systems Science and Engineering (CSSE) provided the
definitive resource for real-time death counts during the pandemic. These counts
reflect times at which deaths were reported to health authorities, not
necessarily when they actually happened. Hence raw JHU death counts are highly
volatile due to reporting idiosyncrasies like day-of-week effects and data
dumps. Hospitalizations are also subject to strong day-of-week effects. We
thus smooth all data with a 7-day trailing average, for both hospitalizations
and deaths.   

Our real-time estimates of HFR actually use data that was available two days
after the date in question. This was done to account for a typical two-day
latency in the most recent data available. In this sense, one can actually view
our real-time estimates as a two-day backcast of the HFR. In the rare event that
counts were still unavailable at a two-day lag, we imputed their values with the
most recently observed data (this is a common scheme, called
last-observation-carried-forward or LOCF).        

\paragraph{Hyperparameters.}

The ratio estimators of the HFR require choices of the lag $\ell$ and delay
distribution $\gamma$. The experiments in Section \ref{sec:results} use a lag of
$\ell=20$ days, which roughly maximizes the cross-correlation between
hospitalizations and deaths over the entire pandemic. For $\gamma$, we use a
discrete gamma distribution, and set its support length to be $d=75$ days, a
conservative choice. For its mean, we use 20 again; this agrees nicely with a UK
analysis that finds a median hospitalization-to-death time of 11 days
\citep{UKdelay},\footnote{Of course, conditions in the UK may be quite different
  from the US. However, we rely on the UK study because it provides the most
  comprehensive information on COVID-19 hospitalization-to-death delay 
  distributions.}   
and a CDC analysis that finds 63\% of COVID-19 deaths are reported in 10 days   
\citep{cdc_deaths_demographic_geographic_2023}. We set the standard deviation to 
18, because the delay distributions fit by the UK study had standard deviations
that were roughly 90\% of their means. 

Section S3 of the Supplement evaluates
the robustness of findings against different hyperparameter values. 
We show our findings do not change across a wide range of lags (Figure S6) and delay distributions (Figure S7).
% Figure \ref{fig:lag} displays a wide range of possible values

\paragraph{Validation data.}


While the true HFR curve is unknown, there are sound ways to approximate it; one  
way is to use estimates from the National Hospital Care Survey (NHCS)
\citep{NHCS2023}, which records weekly HFR based on a representative subset 
of 601 hospitals across the US. These estimates end up being consistently
biased downwards because they are only based on deaths which occur in the
hospital. A CDC analysis \citep{ahmad2023covid} found that roughly 60\% of
COVID-19 deaths occurred in hospitals in 2022, down from nearly 70\% in 2021 and
2022. To account for non-inpatient deaths, we divide the NHCS estimates by these
percentages. Lastly, we smooth the resulting HFR estimates with a spline, via
the \texttt{smooth.spline} function in R (which chooses the smoothness
hyperparameter by minimizing generalized cross-validation error). This results 
in our proxy for the ground truth HFR curve $p_t$.  

This ground truth proxy is a useful benchmark to judge the fidelity of our HFR
estimates; of course, it is not perfect (and derived from a relatively small
subset of hospitals). Results in Section \ref{sec:results} suggest it may be too
high in late 2022. 
Section S2.1 in the Supplement discusses alternative
approximations to the ground truth HFR. 
These alternatives, shown in Figure S3, all exhibit similar qualitative behavior. 
% As a result, this sensitivity analysis reinforces the results of our real-data experiments.

\section{Results}
\label{sec:results}

We study the performance of the ratio estimators in greater depth, on real and 
simulated data. Throughout, we continue to use COVID-19 hospitalizations
reported to the HHS as the primary incidence curve. Code to reproduce all
results is available at
\url{https://github.com/jeremy-goldwasser/Severity-Bias}.            

\subsection{COVID-19 data}
\label{sec:results_real}

Figure \ref{fig:basic_est_vs_gt_figs} displays real-time HFR estimates from
November 2020 to December 2022, which spans the major COVID-19 waves. These
estimates were fit to the data described in Section \ref{sec:setup}. The
real-time hospitalization and death counts exhibit a fair degree of instability,
and recall, these were preprocessed with a 7-day trailing average. Even then,
the convolutional \eqref{eq:conv} and lagged ratio \eqref{eq:lagged} estmators
each had wild spikes, so we further smoothed the estimates from both methods
with a 7-day trailing average. 
Section S3 studies the
sensitivity of the results to the choice of smoothing window in postprocessing.
Figure S5 shows window size has very little qualitative effect on the main shape of the HFR estimates from either method. 

\begin{figure}[t!]
\centering
\begin{subfigure}[b]{\linewidth} 
  \centering
  \includegraphics[width=\linewidth]{Figures/Real/US_ests_realtime.pdf}
  \caption{Convolutional and lagged ratios against approximate ground truth
    HFR. Waves corresponding to the original, Delta, and Omicron variants are highlighted in gray. } 
\end{subfigure}

\bigskip
\begin{subfigure}[b]{\linewidth}
  \centering
  \includegraphics[width=\linewidth]{Figures/Real/hfrs_by_wave.pdf}
  \caption{Zooming in to focus on major variants, with hospitalizations overlaid
    (right y-axis).}
\end{subfigure}

\caption{Comparing ratio estimates to approximate ground truth HFR on real-time
  COVID-19 counts in the US, from November 2020 through December 2022.}
\label{fig:basic_est_vs_gt_figs}
\end{figure}

Overall, both ratio estimators perform poorly---their bias is consistent and 
nontrivial, especially for the lagged estimator. Both respond very slowly to
changes in the HFR. As the HFR declines following the wave in winter 2021, both   
ratios hover near 20\% for several months. More troublingly, they are too slow
to detect the rise in HFR in the early Delta period (summer 2021). If the
purpose of these estimators is to inform stakeholders of increased risks in real
time, they failed during the Delta surge.  

The most significant bias comes in the middle of the Omicron wave in spring
2022. In this period, the HFR remains around 15\% until April, then sharply
declines to 9\% two months later. The ratio estimates first fluctuate around the
true HFR, and then subsequently, both estimates surge as the true HFR nears
its nadir, with the lagged ratio approaching 30\%. This dramatic upswing signals
a serious false alarm.  The analysis in Sections \ref{sec:wellspecified} and
\ref{sec:misspecified} explain each of these failure cases. 

\paragraph{Well-specified analysis.}

We start by analyzing the convolutional ratio with respect to the well-specified
bias expression in Proposition \ref{prop:OracleBias}. While this expression
assumes that the true delay distribution is known, we found that different
choices of delay distribution generally yield similar bias; see Figure S7 in Section 3 of the Supplement. 
This indicates that our convolutional ratio may 
not be far from the oracle (well-specified) ratio. 

Proposition \ref{prop:OracleBias} indicates that the bias moves in the opposite
direction of the true severity rate. This occurs during the Delta wave, when the
HFR rises well before the ratio estimates do. On the other hand, falling HFR
produces positive bias, as observed in the original and Omicron waves.  

The enormity of the bias during Omicron can partially be attributed to the
precipitous decline in hospitalizations, as falling primary incidence has been
shown to exacerbate the bias. Average daily hospitalizations declined from over
20,000 in mid-January to only 1,500 by April 1. Lastly, the delay distribution
is relatively heavy-tailed, because the aggregate deaths here (from JHU) are
aligned by report date. 
We find that this has a substantial impact on the bias, 
as analyzed in Supplement Section S2.1. 
Figure S2 shows a large gap in bias between ratios computed on NCHS versus JHU deaths.

\paragraph{Misspecified analysis.}

The misspecification analysis explains central discrepancies between the
convolutional and lagged ratios. Section \ref{sec:misspecified} discusses why we 
expect \smash{$A_t^\ell < 1$} around the start of a decline in primary
incidence (Heuristic \#2). As a result, the lagged ratio will incur negative misspecification
bias, so it takes lower values than the convolutional ratio. 
We observe this when hospitalizations with the original variant
decline from their peak in mid-January 2021. Throughout February 2021, lagged
estimates are about 2\% below the positively biased convolutional ratios.   

As primary incidence rises, we expect \smash{$A_t^\ell > 1$}, contributing
positive bias relative to the well-specified
ratio (Heuristic \#1). Correspondingly, when hospitalizations surge due to the Delta variant in 
August 2021, the lagged ratio is less negatively biased. Lastly, recall we
expect \smash{$A_t^\ell > 1$} \emph{after} a fall in primary incidence (Heuristic \#3). This
accounts for the lagged ratio having higher bias in April 2022, when
hospitalizations level out from the Omicron surge. There, the lagged HFR (and 
presumably also the misspecification factor \smash{$A_t^\ell$}) hits its maximum
value.   

\paragraph{}

We performed several robustness checks to assess the stability of these
findings. Section S3 compares HFR estimates using finalized counts, rather than the
data available in real time (Figure S4).
It also studies the effect of different
hyperparameter choices (Figures S5-7), and examines the ratio estimators on six US
states (Figure S8). By and large, the ratio estimators yield roughly
the same type of bias throughout.


\subsection{Simulated data}
\label{sec:results_sim}

We further evaluate the ratio estimators in a variety of simulation settings. 
Keeping the primary incidence $X_t$ as hospitalizations reported to the HHS, we simulate deaths based on the convolutional model \eqref{eq:model} without noise. That is, we generate
\[
Y_t = \E[Y_t\given \{X_s\}_{s\leq t}] = \sum_{k=0}^d X_{t-k} \P(\text{die at $t$} \given \text{hospitalized at
  $t-k$}) = \sum_{k=0}^d X_{t-k} \pi_k p_{t-k},
\]

The simulations explore three different underlying HFR curves and two delay distributions. The delay distribution $\pi$ is a discrete gamma with
standard deviation 90\% of its mean. We consider means of 12 and 24 to
compare short and long distributions.
For the HFRs $p_t$, we first use the approximate ground truth given by NHCS
In addition, we mimic the opposite trend by inverting and rescaling this curve. 
We do so with the following formula, preserving the minimum and maximum HFRs:
\[
p^\text{Inv} = \frac{1}{p}\times\frac{\text{min}(p)}{\text{max}(p)}
\]


The third HFR setting is a stationary $p=10\%$ over all time.
This case elucidates the quantity \smash{$A_t^\ell$} that drives the lagged ratio's bias. This value is \smash{$A_t^\ell = \hat{p}_t^\ell/p$}, the lagged ratio itself scaled by a constant. 
% $$\hat p_t^\pi = \frac{Y_t}{\sum X_{t-k}\pi_k} = \frac{E Y_t}{\sum X_{t-k}\pi_k} = \frac{p \sum X_{t-k}\pi_k}{\sum X_{t-k}\pi_k} = p A_t^\pi.$$
To see this, recall that the oracle convolutional ratio is unbiased under stationarity, so Proposition \ref{prop:MispBias} simplifies to
\smash{$\E[\hat{p}_t^\ell \given \{X_s\}_{s\leq t}] = p A_t^\ell$} for the
lagged ratio. Furthermore, \smash{$\E[\hat{p}_t^\ell \given \{X_s\}_{s\leq t}]  
  = \hat{p}_t^\ell$} in this noiseless simulation, so \smash{$A_t^\ell = \hat{p}_t^\ell / p$}. 
$A_t^\gamma$ also is $\hat{p}_t^\gamma / p$ for the well-specified convolutional ratio, since the estimator is unbiased and $A_t^\pi=1$ by definition. 
  % Consequently,
% \smash{$A_t^\ell = \hat{p}_t^\ell / p$}, or in other words, one can identify 
% \smash{$A_t^\ell$} by simply multiplying the curves in the third row by $1/p =
% 10$.   



\begin{figure}[t!]
\centering
\includegraphics[width=\linewidth]{Figures/Simulated/simulated_results_corr_lag.pdf}
\caption{Convolutional and lagged ratios over various simulation settings, with
  three different underlying HFR curves (rows) and two delays (columns). The last row, for stationary HFR, also provides $A_t^\gamma = \hat{p}_t^\gamma/p$.}
\label{fig:sims}
\end{figure}


To estimate the severity rates, the convolutional ratio is well-specified with $\gamma=\pi$.
% For the convolutional ratio, we use $\gamma = \pi$ (the well-specified case). 
For the lagged ratio, we choose the lag $\ell$ by maximizing the
cross-correlation between hospitalizations and deaths. 
In both cases, we do not smooth the data in any capacity. (The same is true for Figures \ref{fig:wellspecified} and \ref{fig:misspecified}.)
 % As a senstivity check, we also experimented with the mean of the delay
 % distribution, as advocated by \citet{lagged_chinese}. The results are shown
 % in Appendix \ref{apx:misc}, and are qualitatively similar. 
 
Figure \ref{fig:sims} shows the results across the six settings in total. As
expected, HFR estimates are significantly more biased when the underlying delay
distribution is longer. This bias is most pronounced with the lagged ratio. For example, even when the true HFR is a constant 10\%, the lagged ratio estimates
hit 13\% under the light-tailed delay, and 15\% under the heavy-tailed one. In
the NCHS HFR setting, it spikes (as we have seen before) as hospitalizations
level out in spring 2022, reaching over 20\% and 25\% under the light- and 
heavy-tailed delays, respectively. Note the convolutional ratio does not share
these dramatic oscillations. By and large, it tracks the general shape of the
true curve, albeit at a delay.
% For the NHCS HFRs, the average delay was 5 days for the light-tailed 
% distribution, and 12 days with heavy tail; these delays were 6 and 14 days for 
% the inverted curve. (To compute the average delay, we again took the maximal
% cross-correlation between the two series.)
Its overall favorable performance rests on the fact that we have chosen in this
simulation to provide it with the benefit of the true delay distribution (no
misspecification).   

The results in Section \ref{sec:misspecified} explain the wide
gap in performance between these estimators. 
% Proposition \ref{prop:MispBias} 
% expresses bias under misspecification as a function of the factor
% \smash{$A_t^\gamma$}. This factor, denoted \smash{$A_t^\ell$} for the lagged
% estimator, can be read off from the third row in Figure \ref{fig:sims}: it is \smash{$A_t^\ell = 10\hat{p}_t^\ell$}, the lagged ratio in blue times a constant factor. To see
% this, recall that given a constant severity rate $p_t = p$, the oracle
% convolutional ratio is unbiased, so \eqref{eq:MispBias} reduces to
% \smash{$\E[\hat{p}_t^\ell \given \{X_s\}_{s\leq t}] = p A_t^\ell$} for the
% lagged ratio. Furthermore, \smash{$\E[\hat{p}_t^\ell \given \{X_s\}_{s\leq t}]  
%   = \hat{p}_t^\ell$}, we simulate deaths without noise. Consequently,
% \smash{$A_t^\ell = \hat{p}_t^\ell / p$}, or in other words, one can identify 
% \smash{$A_t^\ell$} by simply multiplying the curves in the third row by $1/p =
% 10$.   
As anticipated, the lagged ratio is higher than the oracle convolutional
ratio when \smash{$A_t^\ell > 1$}, and lower when \smash{$A_t^\ell <
  1$}. Comparing \smash{$A_t^\ell$} to the estimated HFR curves, the bias moves
very similarly. 
For example, during the Delta and Omicron waves, rapid rises in
hospitalizations produced high values of \smash{$A_t^\ell$}. This accounts for
the spikes in August 2021 and January 2022 (Heuristic \#1). 
Heuristic \#2 dictates the lagged estimator should have lower bias than the well-specified ratio as primary events
fall. We observe this in Delta (September 2021) and Omicron (Februrary 2022).  
Lastly, when hospitalizations level out from
the Omicron surge, \smash{$A_t^\ell$} spikes to 1.2 and 1.5 for the short
and long distributions. This explains the positive bias in spring 2022, per Heuristic \#3.

The bias \eqref{eq:MispBias} rescales the oracle bias and adds a
misspecification term. Studying Figure \ref{fig:sims}, we observe the
misspecification term tends to dominate when \smash{$A_t^\ell$} strays away from 
1. To understand this, consider periods in which the oracle bias is negative. As
introduced in Section \ref{sec:misspecified}, the oracle and misspecification
terms are at odds with each other when this is the case. Invariably, the lagged
ratio moves in the direction of the misspecification term
\smash{$p_t(A_t^\ell-1)$}. In the NHCS HFR setting, for example, the lagged 
estimates spike with $A_t^\ell$ in August 2021. In the inverted setting, the 
lagged bias tracks the down-up-down motion of \smash{$A_t^\ell$} during the
first five months of 2021. That the misspecification term wins out in these
conflicting settings indicates it comprises a disproportionate amount of the
bias. Indeed, the oracle bias is low enough that multiplicative rescaling must 
not have a large effect.  

% For a further example, consider the bias at April 2022 on the middle
% right. The true HFR is 14\%, with the convolutional ratio nearby at
% 15\%. Meanwhile, the lagged ratio peaks at 22.5\%, driven upwards by an
% $A_t^\ell$ of $1.5$. Decomposing the lagged bias of $8.5\%$ with Proposition
% \ref{prop:MispBias}, the oracle term $A_t^\ell \text{Bias}(\hat{p}_t^\pi)$
% equals only $1.5\%$; meanwhile, the misspecification term $p_t(A_t^\ell-1) =
% 7\%$, accounting for the majority of the bias.  

\section{Discussion}

Our analyses and experiments illustrate that practitioners should take caution
when using standard ratio estimators for time-varying severity rates. They
exhibit nontrivial bias as severity rates change, particularly the popular
lagged ratio. If a major purpose of such estimators is to inform stakeholders of
changing risks in real time, then such bias indicates they may fail to do so in
a reliable manner.

Analyzing the bias, as we have done in Propositions \ref{prop:OracleBias} and 
\ref{prop:MispBias}, allows us to form real-time heuristics about what to
expect in practice. For example, based solely on the primary incidence curve, we
generally expect the lagged ratio to make the following errors: 
\begin{itemize}
\item unreasonably high severity estimates when primary incidence is rising
  quickly (Heuristic \#1); 
\item rapid declines when primary incidence is falling quickly (Heuristic \#2); 
\item unexpected surges when primary incidence has leveled out after falling (Heuristic \#3).  
\end{itemize}
Practitioners may be able to adjust their reactions accordingly. For example, if 
the lagged HFR spikes shortly after hospitalizations have declined and reach a
stable low point, then a savvy epidemiologist can temper their alarm with the
knowledge it may well be spurious.  

While the lagged ratio seems ubiquitous in practice, the convolutional ratio
(when  a reasonable estimate of the delay distribution can be formed) can be
better behaved and should probably be favored. While it is still subject to
bias, this tends to be of a smaller magnitude. 

Going beyond, there is still room to improve upon the backward-looking
convolutional ratio. 
% \citet{fusedlasso} proposed an approach that is meant to be
% retrospective in nature, and not real-time. It is also inherently
% forward-looking, and estimates all historical severity rates $p_t$ at once, by
% minimizing  
A promising forward-looking severity estimator was proposed by \citet{fusedlasso}. 
This method obtains all historical severity rates $p_t$ at once, by minimizing  
\[
\sum_t (Y_t - \sum_{j=0}^d X_{t-j}\gamma_j p_{t-j})^2 + 
\lambda \sum_t |p_t - p_{t-1}|,
\]
\noindent where $\lambda \geq 0$ is a parameter that controls the level of
regularization. The regularizer above is a total variation penalty, also called the fused lasso; it produces a piecewise constant fit of the severity rates.
Unlike the convolutional ratio, this method models the relationship between events without assuming severity rates are locally stationary. 
Therefore, it may be a less biased alternative.
Since the severity rates are defined implicitly via optimization, their bias is analytically intractable and must be assessed empirically.
% Understanding its bias merits further empirical investigation. 
% A clear expression for its bias cannot be derived, as its severity rates are the minimum of an optimization program, and lack a closed-form expression.

Unfortunately, while this method was introduced as a real-time tool, it struggles with instability at the most recent timesteps.
Improving its capabilities for real-time estimation, 
% Adapting this model so that it can better produce
% estimates in real-time, 
and extending it to fit smoother severity rates using
trend filtering penalties (see, e.g., \citealp{Tibshirani2014}), are interesting
directions for future work. \citet{Jahja2022} applied trend filtering to a
similar deconvolution problem, reconstructing latent infections from case
reports. Their insights on tail regularization may be useful to stabilize
real-time severity estimates.

% \citet{UKpaper} also proposed a forward-looking method, this one a ratio
% between relevant primary and secondary events. However, this method is not
% applicable in real time, as it uses secondary events after $t$ to compute the
% severity rate. Nevertheless, it is a useful tool for retrospective estimation.  

% Another retrospective tool is aggregate COVID deaths from NCHS, a resource
% that was not available in real time (Appendix~\ref{apx:NCHS_deaths}). Unlike
% JHU, whose aggregates align deaths by report date, NCHS counts deaths on the
% day the actually occurred. As a result, the mean of its delay distribution is 
% considerably lower, so it produces more accurate ratio estimates (Figures
% \ref{fig:sims} and \ref{fig:jhu_vs_nchs}). Analogously, bias is a more serious 
% issue with earlier primary events. For example, case- or infection-fatality 
% ratios may be more biased than hospitalization-fatality ratios.  

Severity rates may be biased in ways beyond the statistical bias our work
focuses on. In Section \ref{sec:setup}, we mentioned that HFR estimation from
line-lists can be subject to ``survivorship bias'': the failure to account for 
deaths occurring outside the hospital \citep{lipsitch2015potential}.
Under-reporting is another central challenge, particularly for CFR. Not all
infections are reported, reporting rates change across time, and severe cases
are more likely to be reported than mild cases \citep{Tsang2021}. \citet{reich2012estimating}
proposed an estimator for a time-invariant \emph{relative} CFR---the ratio of
CFRs between groups---which learns latent reporting rates via the EM
algorithm. \citet{anastasios} applied this in the context of COVID-19. Their
work also identifies other sources of bias, like differences in case definition
and testing eligibility.  
Finally, examining how hyperparameter tuning strategies affect the bias poses an opportunity for future work.

As discussed in Section \ref{sec:defs}, severity rates may be understood in
connection with reproduction numbers. This connection extends to their bias as
well. For example, we  demonstrated that the convolutional ratio is unbiased if
the severity rate and delay distribution in the $d$ time points before $t$ are 
stationary. In a similar vein, \citet{fraser2007} noted that instantaneous $R_t$
is equal to case $R_t$ if conditions remain unchanged. Future work along the
lines of \citet{rt_study} could apply our framework to $R_t$ bias, examining the
fidelity of instantaneous $R_t$ as a proxy for case $R_t$.   
Conversely, one could apply Bayesian perspectives on $R_t$ to the context of severity rates.

% \section*{Supporting Information Legends}

% \textbf{S1 Supplemental Information.} 
% Additional figures, simulation details, and mathematical derivations referenced in the main text.

\section*{Acknowledgements and Financial Disclosure}

We would like to thank members of the Delphi research group for helpful
feedback. 
% This work was supported by Centers for Disease Control and Prevention
% (CDC) grant no.\ 75D30123C15907.   
This study was funded by two grants from the Centers for Disease Control and Prevention (CDC): ``The Delphi Center for Outbreak Analytics and Disease Modeling in Public Health Response'' (no. NU38FT00005), and ``Digital Public Health Surveillance for the 21st Century'' (no. 75D30123C15907). Funders were not involved in this study in any capacity. Ryan Tibshirani received both grants, and used them to fund Jeremy Goldwasser. 

\bibliographystyle{apalike}
\bibliography{refs}

\end{document}
